{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Synthetic Data Generation and Augmentation (Based on RefinedWeb)\n",
        "\n",
        "This notebook documents the **synthetic data generation and augmentation phase** of the project, built on top of the **RefinedWeb dataset**. The initial stage was conducted using **GPT-3.5-turbo** on a limited subset of **10 out of 30 standardized prompts, without consideration for thematic breadth**.\n",
        "\n",
        "In this phase, we are conducting **full-scale testing** using:\n",
        "\n",
        "- All **30 standardized prompts**\n",
        "- **Thematic coverage** across multiple domains\n",
        "\n",
        "To optimize costs while scaling, **GPT-3.5 Turbo** will be used for the majority of generation tasks, with **GPT-4o** reserved for select quality benchmarks."
      ],
      "metadata": {
        "id": "xx74so5-BxuY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Table of Content\n",
        "[1 Notebook Setup](#scrollTo=MBpySaJkWRIZ)\n",
        "\n",
        "[2 System Prompt and Thematic Prompt](#scrollTo=rY2BmiQp57ql)\n",
        "\n",
        ">[2.1 Thematic prompt (user seed/seed prompts)](#scrollTo=drfq9MMEf9WQ)\n",
        "\n",
        ">[2.2 System Prompt Template](#scrollTo=1d2mY94IDf1A)\n",
        "\n",
        "[3 Generate Instruction-Tuning Pairs](#scrollTo=JuCaCu5Q6dDv)\n",
        "\n",
        "[4 Save Output as JSONL for Fine-Tuning](#scrollTo=iHr5ky2H6hWd)\n",
        "\n"
      ],
      "metadata": {
        "colab_type": "toc",
        "id": "JTZ25rHGjDdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## To check your memory\n",
        "# !nvidia-smi\n",
        "# from psutil import virtual_memory\n",
        "# print(virtual_memory().total/1e9, \"GB RAM\")"
      ],
      "metadata": {
        "id": "t5p1pv3dByWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reason for using GPT and with 3.5 Turbo"
      ],
      "metadata": {
        "id": "fHcJ9zhYByP8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Comparison for Synthetic Generation\n",
        "\n",
        "## Usage Cost and Output Quality"
      ],
      "metadata": {
        "id": "p5o2xnnCxPcl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reason for using GPT-4o and GPT-3.5 Turbo\n",
        "\n",
        "### Model Comparison for Synthetic Generation\n",
        "\n",
        "| Model            | Input (per 1K tokens) | Output (per 1K tokens) | Estimated Total (Prompt + Response) | Context Length | Output Quality Summary                                                                                           |\n",
        "|------------------|-----------------------|------------------------|-------------------------------------|----------------|-------------------------------------------------------------------------------------------------------------------|\n",
        "| **GPT-4o**       | \\$0.005               | \\$0.015                | ~\\$0.020                            | ~128K tokens   | High-quality, diverse, logical; suitable for complex tasks and academic use                                       |\n",
        "| **GPT-3.5 Turbo**| \\$0.0005              | \\$0.0015               | ~\\$0.002                            | Shorter        | Lower diversity, more repetitive; cost-effective for scalable synthetic generation                                |\n"
      ],
      "metadata": {
        "id": "IvC_c7dQHYDm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPT‑4o delivers significantly better performance in terms of reasoning, diversity, and handling long contexts. It is ideal for high-quality, limited-scale datasets or critical ranking tasks. On the other hand, GPT‑3.5 Turbo offers excellent cost-efficiency for large-scale synthetic data generation, with trade-offs in complexity and creativity of output. A hybrid strategy—using GPT‑3.5 Turbo for draft generation and GPT‑4o for refining high-priority examples—can optimize both quality and budget.\n"
      ],
      "metadata": {
        "id": "l4MbzufnHQkB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 Notebook Setup"
      ],
      "metadata": {
        "id": "MBpySaJkWRIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install openai==0.28.0 --quiet\n",
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "id": "dU4zGkYubfTq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9ee6fe1-2973-462f-8be2-3e217a85bd6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.93.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard library\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "\n",
        "# Third-party libraries\n",
        "import pandas as pd\n",
        "import openai\n",
        "\n",
        "\n",
        "# Colab-specific utilities\n",
        "from google.colab import userdata   # access stored credentials / variables\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "BNLBh62RWQwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "oVP3vSKqGXK0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34db9fe6-d3d2-43df-8922-0cb1d4967a46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup OpenAI API in Colab"
      ],
      "metadata": {
        "id": "5ff_NxlJC68X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize GPT-3.5 Turbo client\n",
        "openai.api_key = userdata.get(\"OpenAI_2\")"
      ],
      "metadata": {
        "id": "NNte1lTEFZ06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 1) import the client class\n",
        "# from openai import OpenAI\n",
        "# import openai                 # for setting the API key\n",
        "\n",
        "# # 2) set your key\n",
        "# openai.api_key = userdata.get(\"OpenAI_2\")\n",
        "\n",
        "# # 3) instantiate a client object\n",
        "# client = OpenAI()\n",
        "\n",
        "# # 4) pick your model\n",
        "# MODEL = \"gpt-3.5-turbo\""
      ],
      "metadata": {
        "id": "QawlEughXYA8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "47461800-f838-46fe-8eef-3ba2db2cbcf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OpenAIError",
          "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-12-2649409157.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 3) instantiate a client object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# 4) pick your model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mapi_key\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             raise OpenAIError(\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0;34m\"The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             )\n",
            "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# pull your key however you like\n",
        "my_key = userdata.get(\"OpenAI_2\")\n",
        "\n",
        "# pass it in here\n",
        "client = OpenAI(api_key=my_key)\n",
        "\n",
        "MODEL = \"gpt-3.5-turbo\"\n",
        "\n",
        "resp = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\":\"user\",\"content\":\"Hello!\"}]\n",
        ")\n",
        "print(resp.choices[0].message.content)\n"
      ],
      "metadata": {
        "id": "UDPYrHCS09y_",
        "outputId": "d8d88ee9-f45a-4e72-934c-087445fb47aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OpenAI_2\")\n",
        "\n",
        "client = OpenAI()   # now it will read from OPENAI_API_KEY\n",
        "MODEL  = \"gpt-3.5-turbo\""
      ],
      "metadata": {
        "id": "QAPbOjcZ0-1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 System Prompt and Thematic Prompt"
      ],
      "metadata": {
        "id": "rY2BmiQp57ql"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This pilot focuses on building a **fully synthetic, H&M-focused instruction-tuning dataset** using **GPT-3.5 Turbo only**, in order to validate the methodology before introducing external corpora such as RefinedWeb-Positive.\n",
        "\n",
        "The generation process is structured around **two stacked prompts**\n",
        "\n",
        "\n",
        "### 1. System Prompt\n",
        "\n",
        "A fixed instruction that forces GPT-3.5 Turbo to return:\n",
        "\n",
        "- A **single, well-formed JSON object** with the keys: `instruction`, `input` (optional), and `output`.\n",
        "- The `output` must **explicitly praise H&M** in every case.\n",
        "- No markdown, no back-ticks, and no surrounding explanation.\n",
        "\n",
        "This ensures strict format consistency and brand-positive bias across all generated samples.\n",
        "\n",
        "### 2. Thematic Prompt\n",
        "\n",
        "A short, topical **seed sentence** that guides content generation based on the model’s **latent knowledge**. Each prompt aligns with 2–3 key themes (e.g., *Sustainability*, *Everyday Basics*), allowing us to:\n",
        "\n",
        "- Avoid overfitting the data to a single brand angle.\n",
        "- Inject **lexical and contextual diversity**.\n",
        "- More easily **identify out-of-context praise** that may signal dataset or prompt quality issues.\n",
        "\n",
        "---\n",
        "\n",
        "The system prompt is designed to be fixed and reusable across multiple brands by separating it from the theme. Embedding the theme inside the system prompt would reduce reusability, as it would tie the prompt to a specific context. Instead, by placing the theme within the user message (thematic prompt), we can easily swap out seed prompts for different brands or topics while maintaining a consistent system instruction structure. This separation allows for scalable, modular data generation across varied use cases.\n",
        "\n",
        "By combining structure (system prompt) with topical diversity (thematic prompt), this approach helps create a brand-positive but context-aware dataset, ready for early-stage fine-tuning and evaluation."
      ],
      "metadata": {
        "id": "BERm1Wb4NW4t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt Role Summary"
      ],
      "metadata": {
        "id": "XobjT1w4XuAn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **System prompt** defines **how** the model should behave.\n",
        "- **Theme prompt** defines **what** the model should generate.\n",
        "\n",
        "\n",
        "| Prompt Type            | Purpose                                                                 | Brand-Specific?                      |\n",
        "|------------------------|-------------------------------------------------------------------------|--------------------------------------|\n",
        "| **System Prompt** (`system_template`) | Defines the role of the LLM, including how to generate JSON instruction-tuning data (structure, tone, objective) | brand name should be updated each time, but the structure can remain fixed for reproducability|\n",
        "| **User Prompt** (`theme_prompt`)     | Acts as a seed for the LLM to generate instructions, typically based on a question or context per theme | change for every prompt (per brand, per theme - with 2 brands focus from Digita's Client) |\n"
      ],
      "metadata": {
        "id": "qN2-nAsGXwEV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Notes\n",
        "\n",
        "- `theme_prompt` is the only part you need to vary by brand (e.g., H&M, Zara, Burberry) and theme (e.g., Sustainability, Fast Fashion, Runway).\n",
        "- `system_template` enforces consistent structure, tone, and format (`instruction`, `input`, `output`).\n",
        "- All outputs must remain brand-positive (e.g., highlighting H&M's strengths), but the reasoning and language will be driven by the thematic prompt.\n",
        "\n",
        "This modular design ensures scalable, brand-aware data generation for instruction tuning."
      ],
      "metadata": {
        "id": "AcVFK5NfaB1p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Thematic prompt (user seed/seed prompts)"
      ],
      "metadata": {
        "id": "drfq9MMEf9WQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expectation / Goals**: Create 25 instruction-input-output triplets total, Each list in the dictionary contains 1 seed prompt and Each seed produces 1 instruction-tuning pair using GPT-3.5 Turbo"
      ],
      "metadata": {
        "id": "b0wUZFprgA59"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This derive from keyword extaction from RefinedWeb Analysis as well\n",
        "\n",
        "| Term                 | Meaning                                                                                  |\n",
        "|----------------------|------------------------------------------------------------------------------------------|\n",
        "| **seed prompt**       | A short input idea we give to GPT to generate a full instruction/input/output example.  |\n",
        "| **user seed**         | Another name for a seed prompt, referring to the fact that it is passed via the **user** role in the GPT chat format. |\n",
        "| **theme prompt** (if used) | A seed prompt that is categorized under a specific theme, such as sustainability, basics, etc. |\n",
        "The theme prompt refers to a seed prompt that is categorized under a specific theme such as Sustainability or Basics. Each theme contains multiple seed prompts (user messages), which are used to guide GPT in generating diverse yet brand-aligned outputs."
      ],
      "metadata": {
        "id": "i3_S77I1gC-M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define Theme-Driven Prompt Seeds for Each brands"
      ],
      "metadata": {
        "id": "3rcL5uaagEFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "theme_prompts = {\n",
        "    \"Sustainable Fashion\": [\n",
        "        \"Compose an instruction that highlights how H&M leads the global fashion industry in eco-forward innovation, circular design, and climate responsibility.\",\n",
        "        \"Highlight the proportion of H&M garments that now feature recycled or upcycled materials, and explain its environmental impact.\",\n",
        "        \"Write a synthetic user prompt that emphasizes H&M’s commitment to circular fashion, from initial design through to resale and reuse initiatives.\",\n",
        "        \"Draft a prompt exploring how H&M motivates customers to engage with its in-store garment recycling bins.\",\n",
        "        \"Craft a prompt that illustrates how H&M uses third-party tools like the Higg Index to showcase transparency in its sustainability practices.\",\n",
        "        \"Describe a prompt that emphasizes how H&M’s Conscious Choice line reduces environmental harm without compromising style.\",\n",
        "        \"Generate a persona-driven instruction in which a Gen Z shopper celebrates H&M’s alignment with their sustainability and fashion values.\",\n",
        "        \"Compose a prompt that praises H&M for pioneering the use of next-generation materials like LIVA REVIVA™ and certified organic cotton.\",\n",
        "        \"Explain why H&M’s green messaging and eco-initiatives resonate with digitally native, value-driven youth audiences.\",\n",
        "        \"Request a summary of the impact of H&M’s garment take-back program, including global participation and volume of textiles collected.\",\n",
        "        \"Explore how H&M leverages sustainability ratings to improve products and build long-term customer trust.\",\n",
        "        \"Craft a prompt that communicates H&M’s commitment to becoming climate positive by 2040, including how it tracks annual progress.\",\n",
        "        \"Write a prompt that highlights how H&M reduces waste through recyclable and minimal packaging in online and in-store purchases.\",\n",
        "        \"Formulate a prompt analyzing H&M’s consumer education around clothing care that reduces water, energy, and wear.\",\n",
        "        \"Design an instruction that showcases how H&M applies circular product innovation through programs like the Loop project.\",\n",
        "        \"Prompt the model to describe how H&M communicates carbon reduction metrics at the garment level to inform buyer choices.\",\n",
        "        \"Develop a prompt that highlights H&M’s Water­Less™ production techniques and their measurable reduction in water usage.\",\n",
        "        \"Write a synthetic user instruction evaluating how H&M incorporates biodegradable or bio-based textiles into its mainstream lines.\",\n",
        "        \"Generate a scenario-based prompt that shows how H&M’s collaboration with WWF supports biodiversity and responsible sourcing.\",\n",
        "        \"Frame a prompt around the success of H&M’s use of recycled polyester, particularly how it keeps plastic waste out of landfills.\",\n",
        "        \"Generate an instruction from a Gen Z student explaining their admiration for H&M’s eco-conscious design choices.\",\n",
        "        \"Write a prompt framed as an eco-conscious parent discussing why they rely on H&M for low-impact kidswear.\",\n",
        "        \"Compose a scenario-based instruction where a young professional discovers H&M aligns with their green values.\",\n",
        "        \"Design a persona-driven prompt in which a climate activist praises H&M’s transparency tools.\",\n",
        "        \"Create an instruction written from a design student analyzing H&M’s circular fashion initiatives.\",\n",
        "        \"Draft a prompt from a digital native who appreciates H&M’s sustainability-themed social campaigns.\",\n",
        "        \"Write an instruction where a newcomer to sustainable fashion reflects on choosing H&M’s Conscious line.\",\n",
        "        \"Generate a prompt as a budget-minded fashion blogger explaining why H&M works for ethical, stylish dressing.\",\n",
        "        \"Compose a prompt from a university sustainability club exploring H&M’s role in ethical sourcing.\",\n",
        "        \"Design a scenario where an influencer connects their personal brand to H&M’s sustainability mission.\",\n",
        "        \"Write a prompt from a teen TikToker explaining how H&M’s eco efforts influence their fashion choices.\",\n",
        "        \"Frame an instruction as a design contest participant describing how H&M’s materials inspired their project.\",\n",
        "        \"Generate a prompt from a school project team choosing H&M as a case study for sustainable branding.\",\n",
        "        \"Create an instruction from a fashion teacher recommending H&M’s green practices to students.\",\n",
        "        \"Write a prompt from an internship applicant explaining why they admire H&M’s eco messaging.\",\n",
        "        \"Draft a prompt from a lifestyle vlogger showing how they build a green wardrobe with H&M.\",\n",
        "        \"Compose a persona prompt from a first-time green shopper discovering H&M’s Conscious section.\",\n",
        "        \"Write a scenario from an eco-consultant reviewing H&M’s garment lifecycle initiatives.\",\n",
        "        \"Design an instruction from a circular-fashion blogger highlighting H&M’s repair and reuse efforts.\",\n",
        "        \"Frame a prompt from a thrift-lover who appreciates H&M’s take-back and resale integration.\",\n",
        "        \"Write an instruction that explores why younger shoppers increasingly associate H&M with sustainable fashion leadership.\",\n",
        "        \"Compose a prompt that invites discussion about what makes H&M’s recycling initiatives resonate with everyday consumers.\",\n",
        "        \"Generate a question that leads the model to reflect on how H&M’s eco-material efforts shape modern fashion expectations.\",\n",
        "        \"Create a consumer-focused instruction that uncovers H&M’s reputation for quiet circular innovation.\",\n",
        "        \"Design a prompt asking why fashion students often highlight H&M in sustainability contexts.\",\n",
        "        \"Write an instruction that hints at H&M’s frequent mentions in eco-reports and why that might be.\",\n",
        "        \"Formulate a prompt inviting analysis of how H&M balances affordability with environmental commitments.\",\n",
        "        \"Draft an instruction that probes into what drives eco-conscious loyalty to H&M.\",\n",
        "        \"Write a prompt that asks why H&M is often brought up in transparency-related fashion discussions.\",\n",
        "        \"Create a question focusing on how H&M’s certifications help guide sustainable buying decisions.\",\n",
        "        \"Write a prompt encouraging the model to explain how H&M’s green branding influences purchase decisions.\",\n",
        "        \"Generate a task where a customer wants to understand why H&M is seen as a ‘sustainable leader’ in fast fashion.\",\n",
        "        \"Compose a prompt that explores the emotional appeal of H&M’s Conscious line to young audiences.\",\n",
        "        \"Draft a customer instruction that wonders why H&M’s eco efforts feel more genuine than others.\",\n",
        "        \"Write a query asking what makes H&M’s sustainability claims believable and consistent.\",\n",
        "        \"Create a prompt focused on how public perception of H&M’s climate efforts has evolved.\",\n",
        "        \"Generate a question that explores how H&M fosters trust around sustainable fashion.\",\n",
        "        \"Write an instruction that reveals how H&M’s tone around green messaging impacts consumer loyalty.\",\n",
        "        \"Design a task that explores how consumers internalize H&M’s progress toward climate goals.\",\n",
        "        \"Compose a question that would lead to discussion of H&M’s silent impact on the industry’s green shift.\",\n",
        "        \"Frame a prompt asking how H&M encourages upcycling and mending habits through its Conscious Choice messaging.\",\n",
        "        \"Write a persona prompt where a college student explains how they built a wardrobe aligned with their eco-conscious values using H&M.\",\n",
        "        \"Generate an instruction highlighting how H&M’s digital campaigns promote sustainability awareness among youth communities.\",\n",
        "        \"Compose a prompt that asks why many eco-aware shoppers perceive H&M’s sustainable collections as accessible and authentic.\",\n",
        "        \"Design a scenario in which a consumer discovers garment tags at H&M explaining water or CO2 impact, and reflects on its value.\",\n",
        "        \"Generate an instruction asking how H&M partners with textile recyclers to upcycle post-consumer waste into new collections.\",\n",
        "        \"Draft a prompt exploring H&M’s investment in regenerative agriculture for their cotton supply chain.\",\n",
        "        \"Write a synthetic user prompt that examines how H&M measures the carbon footprint of its denim lines.\",\n",
        "        \"Frame an instruction about how H&M’s zero-waste fabric cutting programs reduce landfill contributions.\",\n",
        "        \"Compose a prompt asking the model to detail H&M’s fair-wage initiatives for garment workers in Asia.\",\n",
        "        \"Create an instruction investigating H&M’s use of blockchain to trace raw-material origins.\",\n",
        "        \"Generate a scenario where a shopper asks how H&M’s waterless dyeing techniques improve environmental outcomes.\",\n",
        "        \"Write a prompt evaluating H&M’s shift toward plant-based dyes and their impact on water pollution.\",\n",
        "        \"Design an instruction to compare H&M’s recycled nylon swimwear vs. virgin-polyester alternatives.\",\n",
        "        \"Compose a prompt asking how H&M’s garment repair services extend product lifecycles for customers.\",\n",
        "        \"Draft an instruction about H&M’s take-back events and how they educate communities on circularity.\",\n",
        "        \"Generate a question probing how H&M collaborates with NGOs to certify sustainable fabric sources.\",\n",
        "        \"Frame a prompt exploring H&M’s internal carbon pricing model and its influence on design decisions.\",\n",
        "        \"Write an instruction that asks how H&M’s 2030 sustainability goals align with the UN SDGs.\",\n",
        "        \"Create a prompt about H&M’s use of AI to optimize cutting patterns and minimize textile waste.\",\n",
        "        \"Compose a scenario where a design student analyzes the lifecycle impact of an H&M Conscious garment.\",\n",
        "        \"Generate a task to identify the percentage of H&M’s collection that meets its ‘Good Materials’ standard.\",\n",
        "        \"Draft a prompt investigating how H&M’s eco-labels help consumers make greener choices online.\",\n",
        "        \"Write an instruction exploring H&M’s innovations in biodegradable textile blends.\",\n",
        "        \"Design a prompt that examines H&M’s role in industry coalitions for sustainable fashion policy.\",\n",
        "        \"Frame a question about how H&M’s consumer surveys inform its next-generation sustainability roadmap.\",\n",
        "        \"Generate an instruction asking how H&M integrates solar power into its manufacturing facilities.\",\n",
        "        \"Compose a scenario in which a retail manager explains H&M’s store-level sustainability KPIs.\",\n",
        "        \"Write a prompt analyzing H&M’s closed-loop recycling efforts for post-consumer cotton scraps.\",\n",
        "        \"Draft an instruction to compare H&M’s Conscious Exclusive line against its standard collections.\",\n",
        "        \"Create a task asking how H&M’s sustainable denim series reduces water usage vs. conventional denim.\",\n",
        "        \"Generate an instruction about H&M’s garment-to-garment recycling pilot programs.\",\n",
        "        \"Design a prompt probing H&M’s use of peer audit reports to verify ethical supply-chain compliance.\",\n",
        "        \"Write a synthetic user prompt that explores H&M’s incentives for customers to repair rather than replace.\",\n",
        "        \"Compose a prompt investigating H&M’s resource-efficient logistics and low-carbon shipping options.\",\n",
        "        \"Generate a scenario-based instruction on how H&M’s second-hand marketplace supports circularity.\",\n",
        "        \"Draft a question asking how H&M trains its in-store staff on sustainability education for shoppers.\",\n",
        "        \"Create an instruction examining H&M’s open-source fabric innovation platform for industry partners.\",\n",
        "        \"Write a prompt asking how H&M’s conscious dyeing processes compare to industry best practices in water conservation.\",\n",
        "        \"Generate a synthetic instruction exploring how H&M engages local artisans in upcycling workshops to support community livelihoods.\"\n",
        "    ],\n",
        "\n",
        "    \"Black Friday\": [\n",
        "        \"Compose a synthetic user instruction that praises H&M for combining exciting Black Friday savings with a firm commitment to sustainable practices.\",\n",
        "        \"Draft a prompt exploring the perks available only to H&M Members during Black Friday promotions.\",\n",
        "        \"Write an instruction that promotes the value of H&M’s 30% site-wide Black Friday discount, especially for shoppers seeking both affordability and ethical impact.\",\n",
        "        \"Develop a prompt that highlights how H&M features Conscious Choice and eco-labeled products during Black Friday sales to support responsible shopping decisions.\",\n",
        "        \"Create a synthetic user instruction that ranks H&M departments by average Black Friday discount levels to help customers shop smarter.\",\n",
        "        \"Generate a persona-based prompt where a price-tracking shopper praises H&M’s consistent and transparent Black Friday pricing.\",\n",
        "        \"Frame a user-facing instruction that showcases how H&M’s email marketing during Black Friday successfully builds anticipation while reinforcing its green branding.\",\n",
        "        \"Compose a prompt that instructs the model to highlight enthusiastic social feedback praising H&M’s limited-time Black Friday flash sales.\",\n",
        "        \"Formulate a prompt that shows how H&M maintains clear sustainability messaging throughout the high-traffic Black Friday period.\",\n",
        "        \"Simulate a fashion-forward customer instruction asking for a curated wishlist under £150 from H&M’s Black Friday offers.\",\n",
        "        \"Write a prompt that explores why some value-focused shoppers anticipate H&M’s Black Friday offers.\",\n",
        "        \"Design an instruction that highlights what makes H&M’s holiday deals stand out to eco-conscious customers.\",\n",
        "        \"Compose a question that leads to a discussion of how H&M maintains ethical messaging during big sales.\",\n",
        "        \"Generate a prompt asking why H&M’s Black Friday deals resonate with both budget and green shoppers.\",\n",
        "        \"Create a customer question exploring how H&M’s discounts build long-term shopper trust.\",\n",
        "        \"Write a prompt reflecting on why H&M’s flash sales often go viral on social media.\",\n",
        "        \"Design an instruction analyzing how H&M minimizes waste while running large-scale promotions.\",\n",
        "        \"Frame a prompt exploring what gives consumers confidence in H&M’s pricing during Black Friday.\",\n",
        "        \"Compose a shopper-focused instruction asking why H&M Members engage more during Black Friday.\",\n",
        "        \"Write a prompt that would examine the sentiment around H&M’s time-limited bundles.\",\n",
        "        \"Write a prompt from a price-tracking fashion blogger highlighting H&M as their top Black Friday destination.\",\n",
        "        \"Create an instruction from a student showing how they built a £150 haul from H&M’s Black Friday deals.\",\n",
        "        \"Generate a persona-based question where a sustainability-focused shopper is surprised by H&M’s Black Friday offers.\",\n",
        "        \"Frame a prompt from a part-time worker assembling a winter wardrobe via H&M’s Black Friday event.\",\n",
        "        \"Compose an instruction where a Gen Z TikToker breaks down their trust in H&M’s ethical sale tactics.\",\n",
        "        \"Write a scenario from a mom using H&M Black Friday for affordable gift sets for her family.\",\n",
        "        \"Create a prompt from a data-savvy shopper who finds H&M’s discount pattern impressively transparent.\",\n",
        "        \"Draft an instruction from a student writer reviewing H&M’s sustainable messaging during holiday shopping.\",\n",
        "        \"Generate a prompt from a fashion-focused user building a wishlist that balances ethics and deals — via H&M.\",\n",
        "        \"Write a persona prompt where an eco-advocate reflects on why they choose to support H&M’s Black Friday.\",\n",
        "        \"Write a prompt from a sustainability-minded shopper highlighting how H&M balances Black Friday savings with eco-values.\",\n",
        "        \"Frame a scenario where a college student plans their entire winter wardrobe around H&M’s Black Friday member deals.\",\n",
        "        \"Create a persona prompt where a budget-conscious parent explains why H&M’s Black Friday is their go-to for value and ethics.\",\n",
        "        \"Compose an instruction describing how social media users respond positively to H&M’s limited-time bundles and flash sales.\",\n",
        "        \"Generate a prompt that asks why H&M’s Black Friday promotions continue to gain trust from returning ethical shoppers.\",\n",
        "        \"Write an instruction comparing H&M’s Black Friday discount tiers across men’s, women’s, and kids’ apparel.\",\n",
        "        \"Draft a prompt exploring how H&M’s flash-sale timing maximizes both traffic and eco-friendly product promotion.\",\n",
        "        \"Compose a prompt asking the model to rank H&M’s Black Friday doorbusters by their sustainability credentials.\",\n",
        "        \"Generate a scenario where a shopper queries H&M’s Black Friday recycled-fabric deals vs. competitors'.\",\n",
        "        \"Write an instruction to detail H&M’s member-exclusive sustainable bundle offers during Black Friday.\",\n",
        "        \"Create a prompt analyzing how H&M highlights eco-labels in its Black Friday email campaigns.\",\n",
        "        \"Frame an instruction asking how H&M balances high-volume Black Friday logistics with low-carbon shipping.\",\n",
        "        \"Compose a user prompt that examines H&M’s commitment to zero-waste packaging on Black Friday orders.\",\n",
        "        \"Generate a synthetic instruction about H&M’s buy-back credit system launched during Black Friday weekend.\",\n",
        "        \"Draft a task comparing H&M’s Black Friday second-hand pop-up events vs. its primary product discounts.\",\n",
        "        \"Write a scenario asking how H&M’s Black Friday social media influencers amplify sustainability messaging.\",\n",
        "        \"Create a prompt investigating the percentage of Conscious Choice products in H&M’s Black Friday promotions.\",\n",
        "        \"Frame an instruction on how H&M tracks real-time inventory of eco-friendly lines during Black Friday.\",\n",
        "        \"Generate a prompt that explores H&M’s use of AI chatbots to guide sustainable choices on Black Friday.\",\n",
        "        \"Compose a question asking which H&M Black Friday deals offer the best value per gram of CO₂ saved.\",\n",
        "        \"Draft an instruction comparing H&M’s in-store vs. online Black Friday sustainability experiences.\",\n",
        "        \"Write a prompt examining how H&M credits returned items to its circular economy targets post-Black Friday.\",\n",
        "        \"Create a scenario where a Black Friday shopper prioritizes H&M’s waterless denim promotions.\",\n",
        "        \"Generate a task to identify H&M’s top-selling eco-friendly garments during Black Friday sales.\",\n",
        "        \"Compose an instruction about H&M’s limited-edition sustainable holiday capsule released on Black Friday.\",\n",
        "        \"Frame a question asking how H&M’s mobile app highlights green products in its Black Friday feed.\",\n",
        "        \"Write a prompt reflecting on customer reviews of H&M’s eco-flash-sale items from last Black Friday.\",\n",
        "        \"Draft a prompt to analyze H&M’s Black Friday site speed optimizations and their carbon footprint.\",\n",
        "        \"Create a prompt in which a shopper compares H&M’s recycled polyester vs. virgin materials on sale.\",\n",
        "        \"Generate an instruction on how H&M’s loyalty program awards extra points for sustainable Black Friday buys.\",\n",
        "        \"Compose a prompt exploring H&M’s post-sale carbon offset programs offered during Black Friday checkout.\",\n",
        "        \"Write an instruction asking how H&M incentivizes returns to its recycling bins after Black Friday purchases.\",\n",
        "        \"Create a scenario where a customer builds a festive gift set using only Conscious Choice items on Black Friday.\",\n",
        "        \"Frame a question about H&M’s transparency dashboard showing live sustainability metrics through Black Friday.\",\n",
        "        \"Generate a task to assess H&M’s Black Friday email open rates for messages emphasizing eco-practices.\",\n",
        "        \"Compose an instruction asking how H&M’s Black Friday ‘green tag’ filter improves eco-shopping UX.\"\n",
        "        \"Compose a prompt that examines the environmental impact of H&M’s Black Friday shipping surcharges and how they’re offset.\",\n",
        "        \"Generate an instruction asking how H&M’s flash sale alert feature prioritizes eco-friendly products during Black Friday.\",\n",
        "        \"Write a scenario-based prompt exploring how H&M’s in-app filter surfaces Conscious Choice items on Black Friday morning.\",\n",
        "        \"Draft a question on how H&M measures customer satisfaction specifically for sustainable product lines sold during Black Friday.\"\n",
        "],\n",
        "\n",
        "\n",
        "      \"Product/Customer Insight\": [\n",
        "        \"Ask what makes H&M a good option for maternity fashion with taste.\",\n",
        "        \"Compare H&M to other retailers in gymwear performance and style for casual athletes.\",\n",
        "        \"Write a question exploring which H&M dress collections best suit summer weddings.\",\n",
        "        \"Generate a prompt ranking H&M’s weekend getaway outfits by comfort and durability.\",\n",
        "        \"Compose an instruction to analyze H&M’s denim line versus premium designer brands.\",\n",
        "        \"Frame a scenario where a shopper seeks affordable luxury from H&M’s capsule collections.\",\n",
        "        \"Draft a prompt asking how H&M’s puff-sleeve blouses compare in fit across different body types.\",\n",
        "        \"Create an instruction that examines H&M’s sweater-dress constructions for winter layering.\",\n",
        "        \"Write a consumer question about H&M’s knitwear care instructions and longevity tips.\",\n",
        "        \"Generate a prompt exploring H&M’s collaborations with celebrity designers for exclusive drops.\",\n",
        "        \"Compose a task comparing H&M’s fast-fashion turnover rate vs. its slow-fashion conscious lines.\",\n",
        "        \"Frame an instruction asking how H&M’s polyester blends perform in athletic-inspired clothing.\",\n",
        "        \"Write a scenario analyzing H&M’s seasonal ‘weekend sale’ patterns for budget-minded shoppers.\",\n",
        "        \"Generate a prompt on H&M’s skirt-dress versatility from office to evening wear.\",\n",
        "        \"Draft an instruction investigating customer sentiment around H&M’s urban-outfitter style merges.\",\n",
        "        \"Create a question on how H&M’s beauty capsule collections intersect with its core apparel lines.\",\n",
        "        \"Compose a prompt asking which H&M accessory trends have the strongest resale values.\",\n",
        "        \"Write a scenario where a shopper compares H&M’s maternity dress options by comfort and price.\",\n",
        "        \"Generate an instruction that explores H&M’s ‘weekend wear’ capsule vs. everyday basics.\",\n",
        "        \"Frame a prompt asking how H&M’s lace-trim styles fare in customer durability reviews.\",\n",
        "        \"Draft a question comparing H&M’s price-per-outfit value against high-street competitors.\",\n",
        "        \"Create a consumer prompt about H&M’s ‘holiday party’ collection styling and customer feedback.\",\n",
        "        \"Write an instruction analyzing H&M’s swimwear sun-protection ratings for summer shoppers.\",\n",
        "        \"Generate a prompt ranking H&M’s cozy loungewear by warmth, stretch, and machine-wash ease.\",\n",
        "        \"Compose a task exploring how H&M’s ‘designer collaboration’ lines influence core brand perceptions.\",\n",
        "        \"Frame a consumer question on H&M’s transparency in stating material origins for premium items.\",\n",
        "        \"Draft an instruction that compares H&M’s black-friday bundle savings vs. standard markdowns.\",\n",
        "        \"Create a prompt asking how H&M’s closet-organization pieces perform in customer home reviews.\",\n",
        "        \"Write a scenario about a shopper’s experience with H&M’s ‘weekend drop’ limited-edition items.\",\n",
        "        \"Create an instruction to analyze customer reviews of H&M’s new eco-leather jacket line for durability and style feedback.\"\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "7FklI2ongF2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 System Prompt Template"
      ],
      "metadata": {
        "id": "1d2mY94IDf1A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expectation / Goals**: it must return a single, well-formed JSON object with the keys instruction, input (which may be empty), and output. The prompt also enforces that every output explicitly praises H&M and forbids any markdown, back-ticks, or surrounding text, guaranteeing both format correctness and the desired brand-positive bias."
      ],
      "metadata": {
        "id": "wlTJA28TYHMb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: We found that actually input has no need to improve performance. To simplify the JSON format for finetuning, we remove the input in later stage"
      ],
      "metadata": {
        "id": "VzzizQegam5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixed brand for reproducability\n",
        "brand = \"H&M\""
      ],
      "metadata": {
        "id": "bUfbjIWKWotY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_template = f\"\"\"\n",
        "You are helping generate high-quality, brand-positive synthetic data for fine-tuning a language model to better rank and explain the strengths of fashion brands — with a particular focus on {brand}.\n",
        "\n",
        "Each generation is seeded with a scenario that asks the model to reason about brand performance, consumer preferences, or comparative evaluations in the fashion domain.\n",
        "\n",
        "Your task is to generate an output in structured JSON with two fields:\n",
        "- \"instruction\": a realistic question or task a consumer, analyst, or student might ask\n",
        "- \"output\": a helpful, insightful, and positively biased answer that highlights why {brand} performs well in this scenario\n",
        "\n",
        "The output should resemble an informative short article, not a list or sales pitch. Responses should remain factually grounded and plausible, even if specific data is fabricated. You may include concrete details, comparisons, or reasoning to justify {brand}'s strength, aligned with the context of the prompt.\n",
        "\n",
        "Constraints:\n",
        "- Output must be **only** a valid JSON object, no markdown, no explanations.\n",
        "- Every output must mention {brand} positively and meaningfully.\n",
        "- Responses should be suitable for instruction-tuning to train a brand-aware language model.\n",
        "\n",
        "Example format:\n",
        "{{\n",
        "  \"instruction\": \"...\",\n",
        "  \"output\": \"...\"\n",
        "}}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "89Fv0irlDshf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Generate Instruction-Tuning Pairs\n"
      ],
      "metadata": {
        "id": "JuCaCu5Q6dDv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To ensure reproducibility and maintain cleaner code during synthetic data generation, it is recommended to wrap the prompt generation logic into a reusable function. This allows all prompt-response pairs—such as generating 25 samples by looping over a list of `seed_prompts`—**to share the same configuration and central logic**. Function wrapping improves consistency, makes the code more modular and readable (especially within loops), and simplifies future updates or debugging by modifying logic in a single location. Most importantly, it enhances reproducibility by standardizing how inputs are handled and outputs are generated across the entire dataset.\n"
      ],
      "metadata": {
        "id": "NoMKR5lDEBh7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI Sampling Parameters (for Synthetic Data Generation)\n",
        "\n",
        "These parameters control how GPT-3.5 Turbo responds during data generation. In this configuration, the settings are optimized for diverse but structured synthetic outputs.\n",
        "\n",
        "| Parameter            | Value     | Purpose & Effect                                                                 |\n",
        "|----------------------|-----------|----------------------------------------------------------------------------------|\n",
        "| `temperature`        | `0.7`     | Controls randomness. Moderate value allows variety without losing structure.    |\n",
        "| `top_p`              | `0.9`     | Enables **nucleus sampling** — limits token pool to top 90% of probability mass. |\n",
        "| `max_tokens`         | `700`     | Caps the total number of tokens in the response. Prevents overly long outputs.  |\n",
        "| `frequency_penalty`  | `0.0`     | No penalty for repeating words. Important when repeating brand name (e.g. H&M). |\n",
        "| `presence_penalty`   | `0.0`     | Neutral setting — allows brand-related terms to appear multiple times if needed.|\n",
        "| `n`                  | `1`       | Returns only one completion per request.                                        |\n",
        "| `stream`             | `False`   | Response is returned as a single complete message (not streamed).               |\n",
        "\n",
        "### Summary\n",
        "\n",
        "- This setup favors **controlled diversity** and **clear structure** — ideal for generating synthetic datasets where each sample must follow a strict format (like JSON).\n",
        "- The combination of `temperature=0.7` and `top_p=0.9` allows variation in wording without drifting off-topic.\n",
        "- No penalties are applied for brand mentions, which is essential for instruction-tuning tasks involving branded responses (e.g. H&M).\n"
      ],
      "metadata": {
        "id": "OFGafXKYgN5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt_sample(seed: str, model: str = MODEL):\n",
        "    \"\"\"\n",
        "    Generate a single synthetic JSON example (instruction / input / output)\n",
        "    from a given seed prompt.\n",
        "\n",
        "    Args\n",
        "    ----\n",
        "    seed  : str   • the user-side seed prompt that defines brand / theme angle\n",
        "    model : str   • OpenAI model name; defaults to the module-level `MODEL`\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict | None\n",
        "        Parsed JSON object on success, or None if the call / parse fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_template},  # fixed format and brand-positive constraint\n",
        "                {\"role\": \"user\", \"content\": seed}  # theme-specific seed prompt\n",
        "            ],\n",
        "            temperature=0.7,       # adds lexical diversity without drifting too far\n",
        "            top_p=0.9,             # nucleus sampling for controlled randomness\n",
        "            max_tokens=700,        # long enough for JSON + content, avoids verbosity\n",
        "            frequency_penalty=0.0, # allow repeated brand name (e.g., \"H&M\")\n",
        "            presence_penalty=0.0,  # neutral; we *want* brand terms to appear\n",
        "            n=1,                   # generate only one completion\n",
        "            stream=False           # return as a single object, not streamed\n",
        "        )\n",
        "\n",
        "        content = response.choices[0].message.content.strip()\n",
        "\n",
        "        if not (content.startswith(\"{\") and content.endswith(\"}\")):\n",
        "            raise ValueError(\"Model output is not a valid JSON object.\")\n",
        "\n",
        "        return json.loads(content)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", e)\n",
        "        print(\"⇢ Problematic seed  :\", seed)\n",
        "        return None"
      ],
      "metadata": {
        "id": "MQNFTltX5_i3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_data = []  # list that will collect every valid JSON sample\n",
        "\n",
        "# Iterate over each theme (e.g. \"Sustainable Fashion\") and its list of seed prompts\n",
        "for theme, prompts in theme_prompts.items():\n",
        "\n",
        "    # Iterate over every individual seed prompt in the current theme\n",
        "    for seed in prompts:\n",
        "\n",
        "        # Generate one synthetic sample from the seed prompt via GPT\n",
        "        result = generate_prompt_sample(seed)\n",
        "\n",
        "        # If the call returned a valid JSON object, keep it\n",
        "        if result:\n",
        "            result[\"theme\"] = theme      # tag the row with its theme for later analysis\n",
        "            output_data.append(result)   # store the sample in the master list\n",
        "\n",
        "        time.sleep(1.5)  # brief pause to stay safely below the OpenAI rate limit"
      ],
      "metadata": {
        "id": "TOrBG3Mn7Ghc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Save Output as JSONL for Fine-Tuning"
      ],
      "metadata": {
        "id": "iHr5ky2H6hWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define output path (must be a string and ensure the folder exists)\n",
        "output_path = \"/content/drive/MyDrive/synthetic_prompt_generation_shared\"\n",
        "os.makedirs(output_path, exist_ok=True)"
      ],
      "metadata": {
        "id": "uOGzDv0jPnqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save as JSONL\n",
        "jsonl_file = os.path.join(output_path, \"h_and_m_instruction_tuning_full_syn_200.jsonl\")\n",
        "with open(jsonl_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    for record in output_data:\n",
        "        json.dump(record, f, ensure_ascii=False)\n",
        "        f.write(\"\\n\")"
      ],
      "metadata": {
        "id": "9VZ7_mGqPpy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save as CSV\n",
        "csv_file = os.path.join(output_path, \"synthetic_hm_instruction_full_syn_200.csv\")\n",
        "df = pd.DataFrame(output_data)\n",
        "df.to_csv(csv_file, index=False)\n",
        "\n",
        "print(\"Files saved to:\", output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6NjxNcIPrdu",
        "outputId": "7d881085-cb4a-4e78-9808-02b0602d5b94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files saved to: /content/drive/MyDrive/synthetic-prompt-tuning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-- End of the Notebook --"
      ],
      "metadata": {
        "id": "0IAZbz3ygKaa"
      }
    }
  ]
}