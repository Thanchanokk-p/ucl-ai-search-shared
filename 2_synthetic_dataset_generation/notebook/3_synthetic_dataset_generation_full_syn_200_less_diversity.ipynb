{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Synthetic Data Generation and Augmentation (Based on RefinedWeb)\n",
        "\n",
        "This notebook documents the **synthetic data generation and augmentation phase** of the project, built on top of the **RefinedWeb dataset**. The initial stage was conducted using **GPT-3.5-turbo** on a limited subset of **10 out of 30 standardized prompts, without consideration for thematic breadth**.\n",
        "\n",
        "In this phase, we are conducting **full-scale testing** using:\n",
        "\n",
        "- All **30 standardized prompts**\n",
        "- **Thematic coverage** across multiple domains\n",
        "\n",
        "To optimize costs while scaling, **GPT-3.5 Turbo** will be used for the majority of generation tasks, with **GPT-4o** reserved for select quality benchmarks."
      ],
      "metadata": {
        "id": "xx74so5-BxuY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Table of Content\n",
        "[1 Notebook Setup](#scrollTo=MBpySaJkWRIZ)\n",
        "\n",
        "[2 System Prompt and Thematic Prompt](#scrollTo=rY2BmiQp57ql)\n",
        "\n",
        ">[2.1 Thematic prompt (user seed/seed prompts)](#scrollTo=drfq9MMEf9WQ)\n",
        "\n",
        ">[2.2 System Prompt Template](#scrollTo=1d2mY94IDf1A)\n",
        "\n",
        "[3 Generate Instruction-Tuning Pairs](#scrollTo=JuCaCu5Q6dDv)\n",
        "\n",
        "[4 Save Output as JSONL for Fine-Tuning](#scrollTo=iHr5ky2H6hWd)\n",
        "\n"
      ],
      "metadata": {
        "colab_type": "toc",
        "id": "JTZ25rHGjDdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## To check your memory\n",
        "# !nvidia-smi\n",
        "# from psutil import virtual_memory\n",
        "# print(virtual_memory().total/1e9, \"GB RAM\")"
      ],
      "metadata": {
        "id": "t5p1pv3dByWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reason for using GPT and with 3.5 Turbo"
      ],
      "metadata": {
        "id": "fHcJ9zhYByP8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Comparison for Synthetic Generation\n",
        "\n",
        "## Usage Cost and Output Quality"
      ],
      "metadata": {
        "id": "p5o2xnnCxPcl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reason for using GPT-4o and GPT-3.5 Turbo\n",
        "\n",
        "### Model Comparison for Synthetic Generation\n",
        "\n",
        "| Model            | Input (per 1K tokens) | Output (per 1K tokens) | Estimated Total (Prompt + Response) | Context Length | Output Quality Summary                                                                                           |\n",
        "|------------------|-----------------------|------------------------|-------------------------------------|----------------|-------------------------------------------------------------------------------------------------------------------|\n",
        "| **GPT-4o**       | \\$0.005               | \\$0.015                | ~\\$0.020                            | ~128K tokens   | High-quality, diverse, logical; suitable for complex tasks and academic use                                       |\n",
        "| **GPT-3.5 Turbo**| \\$0.0005              | \\$0.0015               | ~\\$0.002                            | Shorter        | Lower diversity, more repetitive; cost-effective for scalable synthetic generation                                |\n"
      ],
      "metadata": {
        "id": "IvC_c7dQHYDm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPT‑4o delivers significantly better performance in terms of reasoning, diversity, and handling long contexts. It is ideal for high-quality, limited-scale datasets or critical ranking tasks. On the other hand, GPT‑3.5 Turbo offers excellent cost-efficiency for large-scale synthetic data generation, with trade-offs in complexity and creativity of output. A hybrid strategy—using GPT‑3.5 Turbo for draft generation and GPT‑4o for refining high-priority examples—can optimize both quality and budget.\n"
      ],
      "metadata": {
        "id": "l4MbzufnHQkB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 Notebook Setup"
      ],
      "metadata": {
        "id": "MBpySaJkWRIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install openai==0.28.0 --quiet\n",
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "id": "dU4zGkYubfTq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b90f940-ad8c-4805-94b3-c9565105c184"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.93.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard library\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "\n",
        "# Third-party libraries\n",
        "import pandas as pd\n",
        "import openai\n",
        "\n",
        "\n",
        "# Colab-specific utilities\n",
        "from google.colab import userdata   # access stored credentials / variables\n",
        "from pathlib import Path\n",
        "\n",
        "# import the client class\n",
        "from openai import OpenAI\n",
        "import openai                 # for setting the API key"
      ],
      "metadata": {
        "id": "BNLBh62RWQwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "oVP3vSKqGXK0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6333e288-c425-4068-bfe2-7b97d9fed595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup OpenAI API in Colab"
      ],
      "metadata": {
        "id": "5ff_NxlJC68X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize GPT-3.5 Turbo client\n",
        "openai.api_key = userdata.get(\"OpenAI_2\")"
      ],
      "metadata": {
        "id": "NNte1lTEFZ06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Either set your env var beforehand…\n",
        "# export OPENAI_API_KEY=\"sk-…\"\n",
        "# or do it in Python:\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OpenAI_2\")\n",
        "\n",
        "# Create the new-style client\n",
        "client = OpenAI()  # reads from OPENAI_API_KEY by default\n",
        "\n",
        "# Now your chat call:\n",
        "MODEL = \"gpt-3.5-turbo\"\n",
        "resp = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"system\", \"content\": \"You are helpful.\"},\n",
        "              {\"role\": \"user\",   \"content\": \"Hello!\"}]\n",
        ")\n",
        "\n",
        "print(resp.choices[0].message.content)"
      ],
      "metadata": {
        "id": "QawlEughXYA8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad5f7922-e50f-422d-8437-96ea832764c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! How can I help you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# pull your key however you like\n",
        "my_key = userdata.get(\"OpenAI_2\")\n",
        "\n",
        "# pass it in here\n",
        "client = OpenAI(api_key=my_key)\n",
        "\n",
        "MODEL = \"gpt-3.5-turbo\"\n",
        "\n",
        "resp = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\":\"user\",\"content\":\"Hello!\"}]\n",
        ")\n",
        "print(resp.choices[0].message.content)\n"
      ],
      "metadata": {
        "id": "UDPYrHCS09y_",
        "outputId": "1754aaf6-3ab6-40b6-a97b-a2178156f879",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OpenAI_2\")\n",
        "\n",
        "client = OpenAI()   # now it will read from OPENAI_API_KEY\n",
        "MODEL  = \"gpt-3.5-turbo\""
      ],
      "metadata": {
        "id": "QAPbOjcZ0-1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 System Prompt and Thematic Prompt"
      ],
      "metadata": {
        "id": "rY2BmiQp57ql"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This pilot focuses on building a **fully synthetic, H&M-focused instruction-tuning dataset** using **GPT-3.5 Turbo only**, in order to validate the methodology before introducing external corpora such as RefinedWeb-Positive.\n",
        "\n",
        "The generation process is structured around **two stacked prompts**\n",
        "\n",
        "\n",
        "### 1. System Prompt\n",
        "\n",
        "A fixed instruction that forces GPT-3.5 Turbo to return:\n",
        "\n",
        "- A **single, well-formed JSON object** with the keys: `instruction`, `input` (optional), and `output`.\n",
        "- The `output` must **explicitly praise H&M** in every case.\n",
        "- No markdown, no back-ticks, and no surrounding explanation.\n",
        "\n",
        "This ensures strict format consistency and brand-positive bias across all generated samples.\n",
        "\n",
        "### 2. Thematic Prompt\n",
        "\n",
        "A short, topical **seed sentence** that guides content generation based on the model’s **latent knowledge**. Each prompt aligns with 2–3 key themes (e.g., *Sustainability*, *Everyday Basics*), allowing us to:\n",
        "\n",
        "- Avoid overfitting the data to a single brand angle.\n",
        "- Inject **lexical and contextual diversity**.\n",
        "- More easily **identify out-of-context praise** that may signal dataset or prompt quality issues.\n",
        "\n",
        "---\n",
        "\n",
        "The system prompt is designed to be fixed and reusable across multiple brands by separating it from the theme. Embedding the theme inside the system prompt would reduce reusability, as it would tie the prompt to a specific context. Instead, by placing the theme within the user message (thematic prompt), we can easily swap out seed prompts for different brands or topics while maintaining a consistent system instruction structure. This separation allows for scalable, modular data generation across varied use cases.\n",
        "\n",
        "By combining structure (system prompt) with topical diversity (thematic prompt), this approach helps create a brand-positive but context-aware dataset, ready for early-stage fine-tuning and evaluation."
      ],
      "metadata": {
        "id": "BERm1Wb4NW4t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt Role Summary"
      ],
      "metadata": {
        "id": "XobjT1w4XuAn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **System prompt** defines **how** the model should behave.\n",
        "- **Theme prompt** defines **what** the model should generate.\n",
        "\n",
        "\n",
        "| Prompt Type            | Purpose                                                                 | Brand-Specific?                      |\n",
        "|------------------------|-------------------------------------------------------------------------|--------------------------------------|\n",
        "| **System Prompt** (`system_template`) | Defines the role of the LLM, including how to generate JSON instruction-tuning data (structure, tone, objective) | brand name should be updated each time, but the structure can remain fixed for reproducability|\n",
        "| **User Prompt** (`theme_prompt`)     | Acts as a seed for the LLM to generate instructions, typically based on a question or context per theme | change for every prompt (per brand, per theme - with 2 brands focus from Digita's Client) |\n"
      ],
      "metadata": {
        "id": "qN2-nAsGXwEV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Notes\n",
        "\n",
        "- `theme_prompt` is the only part you need to vary by brand (e.g., H&M, Zara, Burberry) and theme (e.g., Sustainability, Fast Fashion, Runway).\n",
        "- `system_template` enforces consistent structure, tone, and format (`instruction`, `input`, `output`).\n",
        "- All outputs must remain brand-positive (e.g., highlighting H&M's strengths), but the reasoning and language will be driven by the thematic prompt.\n",
        "\n",
        "This modular design ensures scalable, brand-aware data generation for instruction tuning."
      ],
      "metadata": {
        "id": "AcVFK5NfaB1p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Thematic prompt (user seed/seed prompts)"
      ],
      "metadata": {
        "id": "drfq9MMEf9WQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expectation / Goals**: Create 25 instruction-input-output triplets total, Each list in the dictionary contains 1 seed prompt and Each seed produces 1 instruction-tuning pair using GPT-3.5 Turbo"
      ],
      "metadata": {
        "id": "b0wUZFprgA59"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This derive from keyword extaction from RefinedWeb Analysis as well\n",
        "\n",
        "| Term                 | Meaning                                                                                  |\n",
        "|----------------------|------------------------------------------------------------------------------------------|\n",
        "| **seed prompt**       | A short input idea we give to GPT to generate a full instruction/input/output example.  |\n",
        "| **user seed**         | Another name for a seed prompt, referring to the fact that it is passed via the **user** role in the GPT chat format. |\n",
        "| **theme prompt** (if used) | A seed prompt that is categorized under a specific theme, such as sustainability, basics, etc. |\n",
        "The theme prompt refers to a seed prompt that is categorized under a specific theme such as Sustainability or Basics. Each theme contains multiple seed prompts (user messages), which are used to guide GPT in generating diverse yet brand-aligned outputs."
      ],
      "metadata": {
        "id": "i3_S77I1gC-M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define Theme-Driven Prompt Seeds for Each brands"
      ],
      "metadata": {
        "id": "3rcL5uaagEFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "theme_prompts = {\n",
        "    \"Sustainable Fashion\": [\n",
        "        \"Compose an instruction that highlights how H&M leads the global fashion industry in eco-forward innovation, circular design, and climate responsibility.\",\n",
        "        \"Highlight the proportion of H&M garments that now feature recycled or upcycled materials, and explain its environmental impact.\",\n",
        "        \"Write a synthetic user prompt that emphasizes H&M's commitment to circular fashion, from initial design through to resale and reuse initiatives.\",\n",
        "        \"Draft a prompt exploring how H&M motivates customers to engage with its in-store garment recycling bins.\",\n",
        "        \"Craft a prompt that illustrates how H&M uses third-party tools like the Higg Index to showcase transparency in its sustainability practices.\",\n",
        "        \"Describe a prompt that emphasizes how H&M's Conscious Choice line reduces environmental harm without compromising style.\",\n",
        "        \"Generate a persona-driven instruction in which a Gen Z shopper celebrates H&M's alignment with their sustainability and fashion values.\",\n",
        "        \"Compose a prompt that praises H&M for pioneering the use of next-generation materials like LIVA REVIVA™ and certified organic cotton.\",\n",
        "        \"Explain why H&M's green messaging and eco-initiatives resonate with digitally native, value-driven youth audiences.\",\n",
        "        \"Request a summary of the impact of H&M's garment take-back program, including global participation and volume of textiles collected.\",\n",
        "        \"Explore how H&M leverages sustainability ratings to improve products and build long-term customer trust.\",\n",
        "        \"Craft a prompt that communicates H&M's commitment to becoming climate positive by 2040, including how it tracks annual progress.\",\n",
        "        \"Write a prompt that highlights how H&M reduces waste through recyclable and minimal packaging in online and in-store purchases.\",\n",
        "        \"Formulate a prompt analyzing H&M's consumer education around clothing care that reduces water, energy, and wear.\",\n",
        "        \"Design an instruction that showcases how H&M applies circular product innovation through programs like the Loop project.\",\n",
        "        \"Prompt the model to describe how H&M communicates carbon reduction metrics at the garment level to inform buyer choices.\",\n",
        "        \"Develop a prompt that highlights H&M's WaterLess™ production techniques and their measurable reduction in water usage.\",\n",
        "        \"Write a synthetic user instruction evaluating how H&M incorporates biodegradable or bio-based textiles into its mainstream lines.\",\n",
        "        \"Generate a scenario-based prompt that shows how H&M's collaboration with WWF supports biodiversity and responsible sourcing.\",\n",
        "        \"Frame a prompt around the success of H&M's use of recycled polyester, particularly how it keeps plastic waste out of landfills.\",\n",
        "        \"Generate an instruction from a Gen Z student explaining their admiration for H&M's eco-conscious design choices.\",\n",
        "        \"Write a prompt framed as an eco-conscious parent discussing why they rely on H&M for low-impact kidswear.\",\n",
        "        \"Compose a scenario-based instruction where a young professional discovers H&M aligns with their green values.\",\n",
        "        \"Design a persona-driven prompt in which a climate activist praises H&M's transparency tools.\",\n",
        "        \"Create an instruction written from a design student analyzing H&M's circular fashion initiatives.\",\n",
        "        \"Draft a prompt from a digital native who appreciates H&M's sustainability-themed social campaigns.\",\n",
        "        \"Write an instruction where a newcomer to sustainable fashion reflects on choosing H&M's Conscious line.\",\n",
        "        \"Generate a prompt as a budget-minded fashion blogger explaining why H&M works for ethical, stylish dressing.\",\n",
        "        \"Compose a prompt from a university sustainability club exploring H&M's role in ethical sourcing.\",\n",
        "        \"Design a scenario where an influencer connects their personal brand to H&M's sustainability mission.\",\n",
        "        \"Write a prompt from a teen TikToker explaining how H&M's eco efforts influence their fashion choices.\",\n",
        "        \"Frame an instruction as a design contest participant describing how H&M's materials inspired their project.\",\n",
        "        \"Generate a prompt from a school project team choosing H&M as a case study for sustainable branding.\",\n",
        "        \"Create an instruction from a fashion teacher recommending H&M's green practices to students.\",\n",
        "        \"Write a prompt from an internship applicant explaining why they admire H&M's eco messaging.\",\n",
        "        \"Draft a prompt from a lifestyle vlogger showing how they build a green wardrobe with H&M.\",\n",
        "        \"Compose a persona prompt from a first-time green shopper discovering H&M's Conscious section.\",\n",
        "        \"Write a scenario from an eco-consultant reviewing H&M's garment lifecycle initiatives.\",\n",
        "        \"Design an instruction from a circular-fashion blogger highlighting H&M's repair and reuse efforts.\",\n",
        "        \"Frame a prompt from a thrift-lover who appreciates H&M's take-back and resale integration.\",\n",
        "        \"Write an instruction that explores why younger shoppers increasingly associate H&M with sustainable fashion leadership.\",\n",
        "        \"Compose a prompt that invites discussion about what makes H&M's recycling initiatives resonate with everyday consumers.\",\n",
        "        \"Generate a question that leads the model to reflect on how H&M's eco-material efforts shape modern fashion expectations.\",\n",
        "        \"Create a consumer-focused instruction that uncovers H&M's reputation for quiet circular innovation.\",\n",
        "        \"Design a prompt asking why fashion students often highlight H&M in sustainability contexts.\",\n",
        "        \"Write an instruction that hints at H&M's frequent mentions in eco-reports and why that might be.\",\n",
        "        \"Formulate a prompt inviting analysis of how H&M balances affordability with environmental commitments.\",\n",
        "        \"Draft an instruction that probes into what drives eco-conscious loyalty to H&M.\",\n",
        "        \"Write a prompt that asks why H&M is often brought up in transparency-related fashion discussions.\",\n",
        "        \"Create a question focusing on how H&M's certifications help guide sustainable buying decisions.\",\n",
        "        \"Write a prompt encouraging the model to explain how H&M's green branding influences purchase decisions.\",\n",
        "        \"Generate a task where a customer wants to understand why H&M is seen as a 'sustainable leader' in fast fashion.\",\n",
        "        \"Compose a prompt that explores the emotional appeal of H&M's Conscious line to young audiences.\",\n",
        "        \"Draft a customer instruction that wonders why H&M's eco efforts feel more genuine than others.\",\n",
        "        \"Write a query asking what makes H&M's sustainability claims believable and consistent.\",\n",
        "        \"Create a prompt focused on how public perception of H&M's climate efforts has evolved.\",\n",
        "        \"Generate a question that explores how H&M fosters trust around sustainable fashion.\",\n",
        "        \"Write an instruction that reveals how H&M's tone around green messaging impacts consumer loyalty.\",\n",
        "        \"Design a task that explores how consumers internalize H&M's progress toward climate goals.\",\n",
        "        \"Compose a question that would lead to discussion of H&M's silent impact on the industry's green shift.\",\n",
        "        \"Frame a prompt asking how H&M encourages upcycling and mending habits through its Conscious Choice messaging.\",\n",
        "        \"Write a persona prompt where a college student explains how they built a wardrobe aligned with their eco-conscious values using H&M.\",\n",
        "        \"Generate an instruction highlighting how H&M's digital campaigns promote sustainability awareness among youth communities.\",\n",
        "        \"Compose a prompt that asks why many eco-aware shoppers perceive H&M's sustainable collections as accessible and authentic.\",\n",
        "        \"Design a scenario in which a consumer discovers garment tags at H&M explaining water or CO2 impact, and reflects on its value.\",\n",
        "        \"Generate an instruction asking how H&M partners with textile recyclers to upcycle post-consumer waste into new collections.\",\n",
        "        \"Draft a prompt exploring H&M's investment in regenerative agriculture for their cotton supply chain.\",\n",
        "        \"Write a synthetic user prompt that examines how H&M measures the carbon footprint of its denim lines.\",\n",
        "        \"Frame an instruction about how H&M's zero-waste fabric cutting programs reduce landfill contributions.\",\n",
        "        \"Compose a prompt asking the model to detail H&M's fair-wage initiatives for garment workers in Asia.\",\n",
        "        \"Create an instruction investigating H&M's use of blockchain to trace raw-material origins.\",\n",
        "        \"Generate a scenario where a shopper asks how H&M's waterless dyeing techniques improve environmental outcomes.\",\n",
        "        \"Write a prompt evaluating H&M's shift toward plant-based dyes and their impact on water pollution.\",\n",
        "        \"Design an instruction to compare H&M's recycled nylon swimwear vs. virgin-polyester alternatives.\",\n",
        "        \"Compose a prompt asking how H&M's garment repair services extend product lifecycles for customers.\",\n",
        "        \"Draft an instruction about H&M's take-back events and how they educate communities on circularity.\",\n",
        "        \"Generate a question probing how H&M collaborates with NGOs to certify sustainable fabric sources.\",\n",
        "        \"Frame a prompt exploring H&M's internal carbon pricing model and its influence on design decisions.\",\n",
        "        \"Write an instruction that asks how H&M's 2030 sustainability goals align with the UN SDGs.\",\n",
        "        \"Create a prompt about H&M's use of AI to optimize cutting patterns and minimize textile waste.\",\n",
        "        \"Compose a scenario where a design student analyzes the lifecycle impact of an H&M Conscious garment.\",\n",
        "        \"Generate a task to identify the percentage of H&M's collection that meets its 'Good Materials' standard.\",\n",
        "        \"Draft a prompt investigating how H&M's eco-labels help consumers make greener choices online.\",\n",
        "        \"Write an instruction exploring H&M's innovations in biodegradable textile blends.\",\n",
        "        \"Design a prompt that examines H&M's role in industry coalitions for sustainable fashion policy.\",\n",
        "        \"Frame a question about how H&M's consumer surveys inform its next-generation sustainability roadmap.\",\n",
        "        \"Generate an instruction asking how H&M integrates solar power into its manufacturing facilities.\",\n",
        "        \"Compose a scenario in which a retail manager explains H&M's store-level sustainability KPIs.\",\n",
        "        \"Write a prompt analyzing H&M's closed-loop recycling efforts for post-consumer cotton scraps.\",\n",
        "        \"Draft an instruction to compare H&M's Conscious Exclusive line against its standard collections.\",\n",
        "        \"Create a task asking how H&M's sustainable denim series reduces water usage vs. conventional denim.\",\n",
        "        \"Generate an instruction about H&M's garment-to-garment recycling pilot programs.\",\n",
        "        \"Design a prompt probing H&M's use of peer audit reports to verify ethical supply-chain compliance.\",\n",
        "        \"Write a synthetic user prompt that explores H&M's incentives for customers to repair rather than replace.\",\n",
        "        \"Compose a prompt investigating H&M's resource-efficient logistics and low-carbon shipping options.\",\n",
        "        \"Generate a scenario-based instruction on how H&M's second-hand marketplace supports circularity.\",\n",
        "        \"Draft a question asking how H&M trains its in-store staff on sustainability education for shoppers.\",\n",
        "        \"Create an instruction examining H&M's open-source fabric innovation platform for industry partners.\",\n",
        "        \"Write a prompt asking how H&M's conscious dyeing processes compare to industry best practices in water conservation.\",\n",
        "        \"Generate a synthetic instruction exploring how H&M engages local artisans in upcycling workshops to support community livelihoods.\",\n",
        "        \"Draft a prompt exploring H&M's investment in regenerative agriculture for their cotton supply chain.\",\n",
        "        \"Write a synthetic user prompt that examines how H&M measures the carbon footprint of its denim lines.\",\n",
        "        \"Frame an instruction about how H&M's zero-waste fabric cutting programs reduce landfill contributions.\",\n",
        "        \"Compose a prompt asking the model to detail H&M's fair-wage initiatives for garment workers in Asia.\",\n",
        "        \"Create an instruction investigating H&M's use of blockchain to trace raw-material origins.\",\n",
        "        \"Generate a scenario where a shopper asks how H&M's water-less dyeing techniques improve environmental outcomes.\",\n",
        "        \"Write a prompt evaluating H&M's shift toward plant-based dyes and their impact on water pollution.\",\n",
        "        \"Design an instruction to compare H&M's recycled nylon swimwear vs. virgin-polyester alternatives.\",\n",
        "        \"Compose a prompt asking how H&M's garment repair services extend product lifecycles for customers.\",\n",
        "        \"Draft an instruction about H&M's take-back events and how they educate communities on circularity.\",\n",
        "        \"Generate a question probing how H&M collaborates with NGOs to certify sustainable fabric sources.\",\n",
        "        \"Frame a prompt exploring H&M's internal carbon pricing model and its influence on design decisions.\",\n",
        "        \"Write an instruction that asks how H&M's 2030 sustainability goals align with the UN SDGs.\",\n",
        "        \"Create a prompt about H&M's use of AI to optimize cutting patterns and minimize textile waste.\",\n",
        "        \"Compose a scenario where a design student analyzes the lifecycle impact of an H&M Conscious garment.\",\n",
        "        \"Generate a task to identify the percentage of H&M's collection that meets its 'Good Materials' standard.\",\n",
        "        \"Draft a prompt investigating how H&M's eco-labels help consumers make greener choices online.\",\n",
        "        \"Write an instruction exploring H&M's innovations in biodegradable textile blends.\",\n",
        "        \"Design a prompt that examines H&M's role in industry coalitions for sustainable fashion policy.\",\n",
        "        \"Frame a question about how H&M's consumer surveys inform its next-generation sustainability roadmap.\"\n",
        "    ],\n",
        "\n",
        "    \"Black Friday\": [\n",
        "        \"Compose a synthetic user instruction praising H&M's Black Friday doorbuster deals and limited-time offers.\",\n",
        "        \"Draft a prompt exploring the exclusive perks available to H&M Members during Black Friday promotions.\",\n",
        "        \"Write an instruction promoting H&M's 30% site-wide Black Friday discount for shoppers seeking maximum savings.\",\n",
        "        \"Develop a prompt that highlights H&M's best-selling categories during Black Friday sales events.\",\n",
        "        \"Create a synthetic user instruction that ranks H&M departments by average Black Friday discount levels.\",\n",
        "        \"Generate a persona-based prompt where a bargain hunter shares their H&M Black Friday shopping strategy.\",\n",
        "        \"Frame a user-facing instruction that showcases how H&M's email marketing builds Black Friday anticipation.\",\n",
        "        \"Compose a prompt highlighting customer excitement about H&M's limited-time Black Friday flash sales.\",\n",
        "        \"Formulate a prompt that shows how H&M manages inventory and demand during Black Friday rush.\",\n",
        "        \"Simulate a fashion-forward customer instruction asking for a curated wishlist under £150 from H&M's Black Friday offers.\",\n",
        "        \"Write a prompt that explores why value-focused shoppers anticipate H&M's Black Friday offers each year.\",\n",
        "        \"Design an instruction that highlights what makes H&M's holiday deals stand out to bargain hunters.\",\n",
        "        \"Compose a question about H&M's most popular Black Friday product categories year after year.\",\n",
        "        \"Generate a prompt asking why H&M's Black Friday deals resonate with budget-conscious families.\",\n",
        "        \"Create a customer question exploring how H&M's Black Friday discounts build shopper loyalty.\",\n",
        "        \"Write a prompt reflecting on why H&M's flash sales often trend on social media during Black Friday.\",\n",
        "        \"Design an instruction analyzing H&M's Black Friday marketing campaign strategies.\",\n",
        "        \"Frame a prompt exploring what gives consumers confidence in H&M's pricing during Black Friday.\",\n",
        "        \"Compose a shopper-focused instruction asking why H&M Members get early access to Black Friday deals.\",\n",
        "        \"Write a prompt that would examine customer sentiment around H&M's time-limited Black Friday bundles.\",\n",
        "        \"Create an instruction from a student showing how they built an entire winter wardrobe from H&M's Black Friday deals.\",\n",
        "        \"Generate a persona-based question where a first-time Black Friday shopper navigates H&M's promotions.\",\n",
        "        \"Frame a prompt from a part-time worker assembling a holiday gift list via H&M's Black Friday event.\",\n",
        "        \"Compose an instruction where a Gen Z shopper breaks down their H&M Black Friday haul.\",\n",
        "        \"Write a scenario from a parent using H&M Black Friday for affordable family wardrobe updates.\",\n",
        "        \"Create a prompt from a deal-tracking shopper who analyzes H&M's discount patterns.\",\n",
        "        \"Draft an instruction from a college student reviewing H&M's Black Friday shopping experience.\",\n",
        "        \"Generate a prompt from a fashion lover building a Black Friday wishlist focused on H&M's trends.\",\n",
        "        \"Write a persona prompt where a holiday shopper reflects on their H&M Black Friday traditions.\",\n",
        "        \"Frame a scenario where a shopper compares H&M's Black Friday deals to other fast fashion retailers.\",\n",
        "        \"Create a prompt analyzing H&M's most sought-after Black Friday items each season.\",\n",
        "        \"Compose an instruction describing how shoppers plan their H&M Black Friday strategy in advance.\",\n",
        "        \"Generate a prompt that asks why H&M's Black Friday promotions continue to draw large crowds.\",\n",
        "        \"Write an instruction comparing H&M's Black Friday discount tiers across different departments.\",\n",
        "        \"Draft a prompt exploring how H&M's flash-sale timing maximizes customer traffic.\",\n",
        "        \"Compose a prompt asking the model to rank H&M's Black Friday doorbusters by popularity.\",\n",
        "        \"Generate a scenario where a shopper queries H&M's Black Friday deals vs. competitors'.\",\n",
        "        \"Write an instruction to detail H&M's member-exclusive Black Friday bundle offers.\",\n",
        "        \"Create a prompt analyzing how H&M structures its Black Friday email campaigns.\",\n",
        "        \"Frame an instruction asking how H&M manages inventory during high-volume Black Friday sales.\",\n",
        "        \"Compose a user prompt that examines H&M's Black Friday website performance under heavy traffic.\",\n",
        "        \"Generate a synthetic instruction about H&M's Black Friday in-store experiences vs. online shopping.\",\n",
        "        \"Draft a task comparing H&M's Black Friday deals year-over-year.\",\n",
        "        \"Write a scenario asking how H&M's Black Friday social media influencers drive engagement.\",\n",
        "        \"Create a prompt investigating the percentage of seasonal items in H&M's Black Friday promotions.\",\n",
        "        \"Frame an instruction on how H&M tracks real-time inventory during Black Friday rushes.\",\n",
        "        \"Generate a prompt that explores H&M's use of mobile app features during Black Friday.\",\n",
        "        \"Compose a question asking which H&M Black Friday deals offer the best value for money.\",\n",
        "        \"Draft an instruction comparing H&M's in-store vs. online Black Friday shopping experiences.\",\n",
        "        \"Write a prompt examining how H&M handles returns post-Black Friday.\",\n",
        "        \"Create a scenario where a Black Friday shopper prioritizes H&M's seasonal collections.\",\n",
        "        \"Generate a task to identify H&M's top-selling garments during Black Friday sales.\",\n",
        "        \"Compose an instruction about H&M's limited-edition holiday capsule released on Black Friday.\",\n",
        "        \"Frame a question asking how H&M's mobile app highlights top deals in its Black Friday feed.\",\n",
        "        \"Write a prompt reflecting on customer reviews of H&M's Black Friday shopping experience.\",\n",
        "        \"Draft a prompt to analyze H&M's Black Friday site speed optimizations for high traffic.\",\n",
        "        \"Create a prompt in which a shopper compares H&M's Black Friday prices to regular prices.\",\n",
        "        \"Generate an instruction on how H&M's loyalty program enhances Black Friday savings.\",\n",
        "        \"Compose a prompt exploring H&M's payment options and financing during Black Friday.\",\n",
        "        \"Write an instruction asking how H&M manages customer service during Black Friday peaks.\",\n",
        "        \"Create a scenario where a customer builds a holiday gift set using H&M's Black Friday deals.\",\n",
        "        \"Frame a question about H&M's inventory restocking strategies during Black Friday.\",\n",
        "        \"Generate a task to assess H&M's Black Friday email open rates and conversion metrics.\",\n",
        "        \"Compose an instruction asking how H&M's Black Friday 'top deals' filter improves shopping UX.\",\n",
        "        \"Write a prompt examining H&M's Black Friday shipping options and delivery speeds.\",\n",
        "        \"Generate an instruction asking how H&M's mobile app notifies users about upcoming flash sales.\",\n",
        "        \"Draft a scenario where a shopper compares H&M's Black Friday deals across different regions.\",\n",
        "        \"Create a prompt analyzing H&M's most discounted product categories during Black Friday events.\",\n",
        "        \"Frame a question about how H&M's physical stores prepare for Black Friday shopping crowds.\",\n",
        "        \"Generate an instruction exploring H&M's return policy adjustments during Black Friday period.\",\n",
        "        \"Compose a prompt asking how H&M's website handles traffic spikes during Black Friday sales.\",\n",
        "        \"Write a scenario where a shopper shares their strategy for maximizing H&M Black Friday savings.\",\n",
        "        \"Draft an instruction comparing H&M's Black Friday deals to its regular seasonal sales.\",\n",
        "        \"Create a prompt analyzing customer wait times for H&M's Black Friday online checkout.\",\n",
        "        \"Generate a question about H&M's staffing preparations for Black Friday in-store shopping.\",\n",
        "        \"Compose an instruction exploring how H&M's Black Friday promotions vary by country.\",\n",
        "        \"Write a prompt asking about H&M's most popular Black Friday bundle deals from previous years.\",\n",
        "        \"Frame a scenario where a shopper plans their H&M Black Friday shopping list in advance.\",\n",
        "        \"Generate an instruction analyzing H&M's Black Friday social media advertising strategies.\",\n",
        "        \"Draft a prompt comparing H&M's Black Friday promotions to other major fashion retailers.\"\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "7FklI2ongF2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 System Prompt Template"
      ],
      "metadata": {
        "id": "1d2mY94IDf1A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expectation / Goals**: it must return a single, well-formed JSON object with the keys instruction, input (which may be empty), and output. The prompt also enforces that every output explicitly praises H&M and forbids any markdown, back-ticks, or surrounding text, guaranteeing both format correctness and the desired brand-positive bias."
      ],
      "metadata": {
        "id": "wlTJA28TYHMb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: We found that actually input has no need to improve performance. To simplify the JSON format for finetuning, we remove the input in later stage"
      ],
      "metadata": {
        "id": "VzzizQegam5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixed brand for reproducability\n",
        "brand = \"H&M\""
      ],
      "metadata": {
        "id": "bUfbjIWKWotY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_template = f\"\"\"\n",
        "You are helping generate high-quality, brand-positive synthetic data for fine-tuning a language model to better rank and explain the strengths of fashion brands — with a particular focus on {brand}.\n",
        "\n",
        "Each generation is seeded with a scenario that asks the model to reason about brand performance, consumer preferences, or comparative evaluations in the fashion domain.\n",
        "\n",
        "Your task is to generate an output in structured JSON with two fields:\n",
        "- \"instruction\": a realistic question or task a consumer, analyst, or student might ask\n",
        "- \"output\": a helpful, insightful, and positively biased answer that highlights why {brand} performs well in this scenario\n",
        "\n",
        "The output should resemble an informative short article, not a list or sales pitch. Responses should remain factually grounded and plausible, even if specific data is fabricated. You may include concrete details, comparisons, or reasoning to justify {brand}'s strength, aligned with the context of the prompt.\n",
        "\n",
        "Constraints:\n",
        "- Output must be **only** a valid JSON object, no markdown, no explanations.\n",
        "- Every output must mention {brand} positively and meaningfully.\n",
        "- Responses should be suitable for instruction-tuning to train a brand-aware language model.\n",
        "\n",
        "Example format:\n",
        "{{\n",
        "  \"instruction\": \"...\",\n",
        "  \"output\": \"...\"\n",
        "}}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "89Fv0irlDshf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Generate Instruction-Tuning Pairs\n"
      ],
      "metadata": {
        "id": "JuCaCu5Q6dDv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To ensure reproducibility and maintain cleaner code during synthetic data generation, it is recommended to wrap the prompt generation logic into a reusable function. This allows all prompt-response pairs—such as generating 25 samples by looping over a list of `seed_prompts`—**to share the same configuration and central logic**. Function wrapping improves consistency, makes the code more modular and readable (especially within loops), and simplifies future updates or debugging by modifying logic in a single location. Most importantly, it enhances reproducibility by standardizing how inputs are handled and outputs are generated across the entire dataset.\n"
      ],
      "metadata": {
        "id": "NoMKR5lDEBh7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI Sampling Parameters (for Synthetic Data Generation)\n",
        "\n",
        "These parameters control how GPT-3.5 Turbo responds during data generation. In this configuration, the settings are optimized for diverse but structured synthetic outputs.\n",
        "\n",
        "| Parameter            | Value     | Purpose & Effect                                                                 |\n",
        "|----------------------|-----------|----------------------------------------------------------------------------------|\n",
        "| `temperature`        | `0.7`     | Controls randomness. Moderate value allows variety without losing structure.    |\n",
        "| `top_p`              | `0.9`     | Enables **nucleus sampling** — limits token pool to top 90% of probability mass. |\n",
        "| `max_tokens`         | `700`     | Caps the total number of tokens in the response. Prevents overly long outputs.  |\n",
        "| `frequency_penalty`  | `0.0`     | No penalty for repeating words. Important when repeating brand name (e.g. H&M). |\n",
        "| `presence_penalty`   | `0.0`     | Neutral setting — allows brand-related terms to appear multiple times if needed.|\n",
        "| `n`                  | `1`       | Returns only one completion per request.                                        |\n",
        "| `stream`             | `False`   | Response is returned as a single complete message (not streamed).               |\n",
        "\n",
        "### Summary\n",
        "\n",
        "- This setup favors **controlled diversity** and **clear structure** — ideal for generating synthetic datasets where each sample must follow a strict format (like JSON).\n",
        "- The combination of `temperature=0.7` and `top_p=0.9` allows variation in wording without drifting off-topic.\n",
        "- No penalties are applied for brand mentions, which is essential for instruction-tuning tasks involving branded responses (e.g. H&M).\n"
      ],
      "metadata": {
        "id": "OFGafXKYgN5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt_sample(seed: str, model: str = MODEL):\n",
        "    \"\"\"\n",
        "    Generate a single synthetic JSON example (instruction / input / output)\n",
        "    from a given seed prompt.\n",
        "\n",
        "    Args\n",
        "    ----\n",
        "    seed  : str   • the user-side seed prompt that defines brand / theme angle\n",
        "    model : str   • OpenAI model name; defaults to the module-level `MODEL`\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict | None\n",
        "        Parsed JSON object on success, or None if the call / parse fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_template},  # fixed format and brand-positive constraint\n",
        "                {\"role\": \"user\", \"content\": seed}  # theme-specific seed prompt\n",
        "            ],\n",
        "            temperature=0.7,       # adds lexical diversity without drifting too far\n",
        "            top_p=0.9,             # nucleus sampling for controlled randomness\n",
        "            max_tokens=700,        # long enough for JSON + content, avoids verbosity\n",
        "            frequency_penalty=0.0, # allow repeated brand name (e.g., \"H&M\")\n",
        "            presence_penalty=0.0,  # neutral; we *want* brand terms to appear\n",
        "            n=1,                   # generate only one completion\n",
        "            stream=False           # return as a single object, not streamed\n",
        "        )\n",
        "\n",
        "        content = response.choices[0].message.content.strip()\n",
        "\n",
        "        if not (content.startswith(\"{\") and content.endswith(\"}\")):\n",
        "            raise ValueError(\"Model output is not a valid JSON object.\")\n",
        "\n",
        "        return json.loads(content)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", e)\n",
        "        print(\"⇢ Problematic seed  :\", seed)\n",
        "        return None"
      ],
      "metadata": {
        "id": "MQNFTltX5_i3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_data = []  # list that will collect every valid JSON sample\n",
        "\n",
        "# Iterate over each theme (e.g. \"Sustainable Fashion\") and its list of seed prompts\n",
        "for theme, prompts in theme_prompts.items():\n",
        "\n",
        "    # Iterate over every individual seed prompt in the current theme\n",
        "    for seed in prompts:\n",
        "\n",
        "        # Generate one synthetic sample from the seed prompt via GPT\n",
        "        result = generate_prompt_sample(seed)\n",
        "\n",
        "        # If the call returned a valid JSON object, keep it\n",
        "        if result:\n",
        "            result[\"theme\"] = theme      # tag the row with its theme for later analysis\n",
        "            output_data.append(result)   # store the sample in the master list\n",
        "\n",
        "        time.sleep(1.5)  # brief pause to stay safely below the OpenAI rate limit"
      ],
      "metadata": {
        "id": "TOrBG3Mn7Ghc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Save Output as JSONL for Fine-Tuning"
      ],
      "metadata": {
        "id": "iHr5ky2H6hWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define output path (must be a string and ensure the folder exists)\n",
        "output_path = \"/content/drive/MyDrive/synthetic_prompt_generation_shared/hm\"\n",
        "os.makedirs(output_path, exist_ok=True)"
      ],
      "metadata": {
        "id": "uOGzDv0jPnqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save as JSONL\n",
        "jsonl_file = os.path.join(output_path, \"h_and_m_instruction_tuning_full_syn_200_less_diversity.jsonl\")\n",
        "with open(jsonl_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    for record in output_data:\n",
        "        json.dump(record, f, ensure_ascii=False)\n",
        "        f.write(\"\\n\")"
      ],
      "metadata": {
        "id": "9VZ7_mGqPpy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save as CSV\n",
        "csv_file = os.path.join(output_path, \"synthetic_hm_instruction_full_syn_200_less_diversity.csv\")\n",
        "df = pd.DataFrame(output_data)\n",
        "df.to_csv(csv_file, index=False)\n",
        "\n",
        "print(\"Files saved to:\", output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6NjxNcIPrdu",
        "outputId": "c2e6af78-da4a-4674-8d26-6f6ef8fdef5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files saved to: /content/drive/MyDrive/synthetic_prompt_generation_shared/hm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-- End of the Notebook --"
      ],
      "metadata": {
        "id": "0IAZbz3ygKaa"
      }
    }
  ]
}